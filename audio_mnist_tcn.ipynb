{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "audio_mnist_tcn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PHM5ZomKiMy"
      },
      "source": [
        "# Predicting numbers from raw audio waveforms\n",
        "## Training a temporal convolutional neural network\n",
        "In this notebook we will analyzing audio recordings from the spoken digits dataset.\n",
        "\n",
        "A detailed description of the **Free Spoken Digit Dataset (FSDD)** dataset can be found [here](https://github.com/Jakobovski/free-spoken-digit-dataset)\n",
        "\n",
        "For this exercise, we will use a network architecture inspired by the so called \"Temporal Convolutional Network\" (TCN) that was proposed in [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/pdf/1803.01271.pdf) by Bai et al. developed with Tensorflow.\n",
        "\n",
        "TCN are well suited to work with very long input sequences such as raw audio waveforms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fpLWvkZKfxR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from pathlib import Path\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpLNTekCsJRo"
      },
      "source": [
        "## Preparing the **Free Spoken Digit Dataset (FSDD)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A71LEAJN11P"
      },
      "source": [
        "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq3fPX43sRtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rB0CmOhsSlo"
      },
      "source": [
        "#### Loading the metadata from the filesystem\n",
        "First we will be loading the dataset metainformation into memory. \n",
        "\n",
        "By splitting the filename we can derive the required information.\n",
        "Files are named in the following format: `{digitLabel}_{speakerName}_{index}.wav` Example: `7_jackson_32.wav`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavhLavYOAkN"
      },
      "source": [
        "def load_metadata(root_dir='free-spoken-digit-dataset'):\n",
        "    recordings_path = Path(root_dir) / 'recordings'\n",
        "    data = []\n",
        "    for path in recordings_path.glob('*.wav'):\n",
        "      data.append((str(path), *path.stem.split('_')))\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['path', 'label', 'speaker', 'iteration'])\n",
        "    df.label = df.label.apply(int)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZq2vap3PIYv"
      },
      "source": [
        "metadata = load_metadata()\n",
        "metadata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e968wAoXPOIO"
      },
      "source": [
        "SAMPLING_RATE=16_000\n",
        "MAX_DURATION_S=0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn4mxafSsuId"
      },
      "source": [
        "#### Loading the audio waveform from the filesystem\n",
        "Next we use librosa to load the waveform from the filesystem and convert the loaded data into `tf.data.Dataset`.\n",
        "\n",
        "Can you derive what is happening in `load_audio`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpSJxlOUPpuS"
      },
      "source": [
        "def load_audio(path, sampling_rate=SAMPLING_RATE, duration_s=MAX_DURATION_S):\n",
        "    audio = np.zeros(int(duration_s * sampling_rate))\n",
        "    waveform, __ = librosa.load(path, sr=sampling_rate)\n",
        "    waveform = waveform[:len(audio)]\n",
        "    audio[:len(waveform)] = waveform\n",
        "    return audio\n",
        "\n",
        "def load_melspectrogram(path, sampling_rate=SAMPLING_RATE, duration_s=MAX_DURATION_S):\n",
        "  waveform = load_audio(path, sampling_rate, duration_s)\n",
        "  M = librosa.feature.melspectrogram(y=waveform, sr=SAMPLING_RATE)\n",
        "  M_db = librosa.power_to_db(M, ref=np.max)\n",
        "  return M_db\n",
        "\n",
        "def load_mfcc(path, sampling_rate=SAMPLING_RATE, duration_s=MAX_DURATION_S):\n",
        "  waveform = load_audio(path, sampling_rate, duration_s)\n",
        "  mfcc = librosa.feature.mfcc(y=waveform, sr=sampling_rate)\n",
        "  return mfcc\n",
        "\n",
        "def build_tf_dataset(metadata):\n",
        "    data = [load_audio(path) for path in tqdm.tqdm(metadata.path, desc='Loading audio')]\n",
        "    return tf.data.Dataset.from_tensor_slices((data, metadata.label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFIXb1k-tDo4"
      },
      "source": [
        "### Splitting the data into train and test\n",
        "Now that we have loaded the required metadata into memory we have to split the dataset into train and test. We want 75% of the data to be in the training and 25% in the test set\n",
        "\n",
        "**NOTE:** We have multiple recordings from the same speaker. To avoid that informartion is leaking from the training into the test dataset we want to make sure that each speaker either appears one or the other dataset. This is called a stratified sample split\n",
        "\n",
        "**NOTE:** Documentation for [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA2p8CC8P8Ha"
      },
      "source": [
        "##########################\n",
        "## YOUR CODE HERE START ##\n",
        "##########################\n",
        "\n",
        "# Split the data into train an test\n",
        "# The test size should be 25% of the entire dataset\n",
        "# Ensure to perform a stratified split along the speaker\n",
        "\n",
        "train_dataset, test_dataset, train_labels, test_labels = train_test_split(\n",
        "    metadata, \n",
        "    ...\n",
        ")\n",
        "\n",
        "##########################\n",
        "## YOUR CODE HERE END ##\n",
        "##########################\n",
        "\n",
        "print(f\"Train set: {len(train_dataset)}\\nTest set: {len(test_dataset)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir0gDmJXXIdq"
      },
      "source": [
        "train_tf_dataset = build_tf_dataset(train_dataset)\n",
        "test_tf_dataset = build_tf_dataset(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Yajd7Vt__5"
      },
      "source": [
        "### Visualizing the dataset\n",
        "Now that we have converted the input data into a Tensorflow dataset we want to visualize the data to get a better intuition.\n",
        "\n",
        "Do you see how the amplitudes in the raw audiowaveform are being represented in the spectograms?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvj-GWy9VBEN"
      },
      "source": [
        "def visualize_audio(audio, label, sr=SAMPLING_RATE):\n",
        "  fig, ax = plt.subplots(1, 4, figsize=(20, 4))\n",
        "  fig.suptitle(f'Label {label}')\n",
        "  duration = len(audio) / sr\n",
        "  t = np.linspace(0, duration, len(audio))\n",
        "  ax[0].plot(t, audio)\n",
        "  ax[0].set_title('waveform')\n",
        "  ax[0].set_xlabel('Time')\n",
        "\n",
        "  D = librosa.stft(audio)  # STFT of y\n",
        "  S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "  ax[1].set(title='Spectogram display')\n",
        "  img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[1])\n",
        "  fig.colorbar(img, ax=ax[1], format=\"%+2.f dB\")\n",
        "\n",
        "  M = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "  M_db = librosa.power_to_db(M, ref=np.max)\n",
        "  img = librosa.display.specshow(M_db, y_axis='mel', x_axis='time', ax=ax[2])\n",
        "  ax[2].set(title='Mel spectrogram display')\n",
        "  fig.colorbar(img, ax=ax[2], format=\"%+2.f dB\")\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "  img = librosa.display.specshow(mfcc, y_axis='mel', x_axis='time', ax=ax[3])\n",
        "  ax[3].set(title='Mel Frequency Cepstral Coefficients')\n",
        "  fig.colorbar(img, ax=ax[3])\n",
        "  IPython.display.display(Audio(data=audio, rate=sr, embed=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0CxQ20sR1iK"
      },
      "source": [
        "##########################\n",
        "## YOUR CODE HERE START ##\n",
        "##########################\n",
        "\n",
        "for (audio, label) in train_tf_dataset.take(3):\n",
        "\n",
        "    # pass in the waveform and the corresponding label\n",
        "    ...\n",
        "\n",
        "##########################\n",
        "## YOUR CODE HERE END ##\n",
        "##########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz3CWTtwUhO2"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_PVgC5Yyq8"
      },
      "source": [
        "train_tf_dataset = (train_tf_dataset\n",
        "                    .shuffle(buffer_size=len(train_dataset), reshuffle_each_iteration=True)\n",
        "                    .repeat(EPOCHS)\n",
        "                    .batch(BATCH_SIZE))\n",
        "\n",
        "test_tf_dataset = (test_tf_dataset\n",
        "                    .batch(BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgeiBcd1uk9g"
      },
      "source": [
        "## Model creation\n",
        "Here we build our model using a TCN model.\n",
        "We will be using the raw audio waveform as input into a simple TCNN-stack. The last layer will translate the hidden states into mutli-class probabilities bewtween 0 and 1.\n",
        "\n",
        "For the TCN model you will use a simple architecture composed of a stack of  convolutional and maxpooling layers connected to a fully connected output with 10 units since there are 10 categories.\n",
        "\n",
        "In a proper TCN model we would ensure that the receptive field size of the model is large enough to caputre the entire input sequence and then we would select a particular entry of the resulting feature map. Here, for simplicity we build a stack of convolutions and maxpooling and flatten the resulting feature map to feed it into our dense layer.\n",
        " \n",
        "Define the model using Keras' [Functional API](https://keras.io/guides/functional_api/):\n",
        " \n",
        "**NOTE:** Documentation for [Conv1D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D), [MaxPool1D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool1D), [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer\n",
        " \n",
        "\n",
        "**NOTE**: This is a multi-class classification problem. Think about the correct activation function for this kind of problem.\n",
        "\n",
        "**NOTE**: we want to exponentially increase the `dilation_rate` of the Conv1D with increasing depth (1, 2, 4, 8...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91qGj_3OY61V"
      },
      "source": [
        "def build_model(max_len=int(SAMPLING_RATE * MAX_DURATION_S)):\n",
        "    \"\"\" add binary classification to pretrained model\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tf.keras.layers.Input(\n",
        "        shape=(max_len, 1), dtype=tf.float32, name=\"inputs\"\n",
        "    )\n",
        "\n",
        "    ##########################\n",
        "    ## YOUR CODE HERE START ##\n",
        "    ##########################\n",
        "    \n",
        "    # build a TCN classification stack \n",
        "    # on top of the raw inputs\n",
        "\n",
        "    # experiment with different depth and see how it affects the number of params\n",
        "    # and the performance of the model\n",
        "    depth = 8\n",
        "    stack = inputs\n",
        "    for i in range(depth):\n",
        "        # exponentially increase the dilation_rate\n",
        "        dilation_rate = ...\n",
        "\n",
        "        # define the 1D convolution with 25 filte and a kernel size of 8\n",
        "        # use the dilation rate defined above\n",
        "        # make sure to use causal convolutions\n",
        "        stack = ...\n",
        "\n",
        "        # Reduce the size of the feature map using max pooling\n",
        "        stack = ...\n",
        "\n",
        "        # Use an activation function on top of the resulting feature map\n",
        "        stack = ...\n",
        "\n",
        "    stack = tf.keras.layers.Flatten()(stack)\n",
        "    output = tf.keras.layers.Dense(10, activation='softmax')(stack)\n",
        "\n",
        "    ##########################\n",
        "    ## YOUR CODE HERE END ##\n",
        "    ##########################\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDawXbjjd2sR"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoqSAns0eNIC"
      },
      "source": [
        "#### Finalizing the model\n",
        "Now that we successfully created our model, we have to finalize it by defining the loss that has to be minimized and which optimizier we want to use.\n",
        "\n",
        "The Tensorflow documentation lists all available [losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses) and [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) you should choose from.\n",
        "\n",
        "**NOTE**: This is a multi-class classification problem. Think about the correct loss function for this kind of problem. Check how the labels are defined \n",
        "\n",
        "**NOTE**: Make sure to initialize your optimizer with the learning rate that was defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBDhkjzYd48F"
      },
      "source": [
        "##########################\n",
        "## YOUR CODE HERE START ##\n",
        "##########################\n",
        "\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Create an instance of an Adam optimizer with the learning rate defined above \n",
        "# Define the loss to be minimized in this classification problem\n",
        "optimizer = ...\n",
        "loss = ...\n",
        "\n",
        "model.compile(optimizer, loss=loss, metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "##########################\n",
        "## YOUR CODE HERE END ##\n",
        "##########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0NQ4LYNefS9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmdpe_-neh8L"
      },
      "source": [
        "## Model training\n",
        "Now we are ready to train model on our dataset\n",
        "We will be monitoring the training process using tensorboard. Once the training is launche you will be able to inspect logged metrics (under scalars) and track the the progress. \n",
        "\n",
        "In the graph section you can look at a visual representation of your model. Can you find your classification stack in the graph?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6pAt8LxeiSw"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CcJSvUWejmA"
      },
      "source": [
        "hist = model.fit(\n",
        "    train_tf_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=int(np.floor((len(train_dataset) / BATCH_SIZE))),\n",
        "    validation_data=test_tf_dataset,\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "               tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True),\n",
        "               tf.keras.callbacks.TensorBoard(f'logs/{datetime.now()}')\n",
        "               ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD7WBzQJvxVe"
      },
      "source": [
        "### Training metrics\n",
        "Lets inspect the training history to see how the losses and metrics behaved during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhSURBVjhau4"
      },
      "source": [
        "history = pd.DataFrame({'epoch': hist.epoch, **hist.history}).set_index('epoch')\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLYGgxsBicTN"
      },
      "source": [
        "history.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jCmDJO3v1tY"
      },
      "source": [
        "## Model evaluation\n",
        "Lets have a look how well the model is preforming on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXJu4XMHieNX"
      },
      "source": [
        "predictions = model.predict(test_tf_dataset, batch_size=BATCH_SIZE, verbose=2, use_multiprocessing=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov-yAg8RigjH"
      },
      "source": [
        "report = metrics.classification_report(y_true=test_labels, \n",
        "                                       y_pred=predictions.argmax(axis=1))\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL18p2k-isgd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}